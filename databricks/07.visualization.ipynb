{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5df6671f-f04a-4fc4-896d-6b455edc1135",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, year, month, dayofmonth, sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ad7a4c1-3205-4312-b85f-2ac069365990",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Critérios de Busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25986f52-ffa0-4ef1-8341-0c9d8199a5f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Search_Criteria:\n",
    "    def __init__(self, subject, keywords):\n",
    "        self.__subject = subject # \"genomics\"\n",
    "        self.__keywords = keywords # [\"DNA\", \"genetics\", \"treatment\"]\n",
    "    \n",
    "\n",
    "    # Adicionar palavra chave\n",
    "    def add_keyworkd(self, new_keyword):\n",
    "        self.__keywords.append(new_keyword)\n",
    "\n",
    "\n",
    "    # Remover palavra chave\n",
    "    def remove_keyworkd(self, old_keyword):\n",
    "        self.__keywords.pop(self.__keywords.index(old_keyword))\n",
    "\n",
    "    @property\n",
    "    def subject(self):\n",
    "        return self.__subject\n",
    "    \n",
    "    @subject.setter\n",
    "    def subject(self, new_subject):\n",
    "        self.__subject = new_subject\n",
    "\n",
    "    @property\n",
    "    def keywords(self):\n",
    "        return self.__keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18d55d0f-85ec-4066-8648-9a23da280c91",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Rotina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "008a124b-046b-40c6-8002-794edc183360",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Instanciando objeto de buscas\n",
    "criteria = Search_Criteria(\"genomics\", [\"DNA\", \"genetics\", \"treatment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "349e2f65-7063-4134-bbdb-29a1bb929ab5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Caminho para a tabela delta\n",
    "delta_table_path = \"/FileStore/Projeto/delta\"\n",
    "\n",
    "# Ler a tabela Delta\n",
    "df = spark.read.format(\"delta\").load(delta_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d1fffa5-309a-49a3-a5ca-3cde58ab2942",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5e88ad7-f36e-46c5-8218-51f82d5c7b9c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+-----+\n|year|month|day|count|\n+----+-----+---+-----+\n|2024|   10| 10|   39|\n|2024|    9| 25|   29|\n|2024|    9| 19|   29|\n|2024|    9| 26|   27|\n|2024|    9| 23|   25|\n|2024|    9| 18|   25|\n|2024|   10| 16|   25|\n|2024|   10| 11|   23|\n|2024|    9| 20|   22|\n|2024|    9| 17|   22|\n|2024|   10|  1|   21|\n|2024|   10| 17|   20|\n|2024|   10| 14|   20|\n|2024|   10| 18|   19|\n|2024|    9| 30|   18|\n|2024|   10| 15|   18|\n|2024|   10|  4|   18|\n|2024|    9| 16|   17|\n|2024|    9| 28|   17|\n|2024|   10|  2|   16|\n+----+-----+---+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Agrupamento por ano, mês e dia\n",
    "df_time_stats = df.groupBy(\n",
    "    year(col(\"data_publicacao\")).alias(\"year\"),\n",
    "    month(col(\"data_publicacao\")).alias(\"month\"),\n",
    "    dayofmonth(col(\"data_publicacao\")).alias(\"day\")).count()\n",
    "\n",
    "# Ordenar pela soma\n",
    "df_time_stats = df_time_stats.orderBy(col(\"count\").desc())\n",
    "\n",
    "# Exibir os resultados\n",
    "df_time_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dabea5a7-eae7-48c1-87c6-e9709981894a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n|               fonte|               autor|count|\n+--------------------+--------------------+-----+\n|      ETF Daily News|     MarketBeat News|  189|\n|       GlobeNewswire|Research and Markets|   39|\n|       Investing.com|       Investing.com|   24|\n|       Science Daily|                NULL|   18|\n|          Biztoc.com|      marketbeat.com|   17|\n|Investor's Busine...|Investor's Busine...|    9|\n|      Financial Post|       GlobeNewswire|    5|\n|National Institut...|                NULL|    5|\n|             Cdc.gov|                NULL|    5|\n|      Financial Post|       Business Wire|    4|\n|       GlobeNewswire|Transparency Mark...|    4|\n|           [Removed]|                NULL|    4|\n|       GlobeNewswire|SkyQuest Technolo...|    3|\n|        Stanford.edu|                NULL|    3|\n|       GlobeNewswire|DelveInsight Busi...|    3|\n|       GlobeNewswire|Dimension Market ...|    3|\n|        Histalk2.com|         Mr. HIStalk|    3|\n|National Institut...|          NCBI Staff|    3|\n|             Fortune|      Lila MacLellan|    2|\n|                 CNA|                NULL|    2|\n+--------------------+--------------------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Agrupamento por fonte e autor\n",
    "df_source_author_stats = df.groupBy(\"fonte\", \"autor\").count()\n",
    "\n",
    "# Ordenar pela soma\n",
    "df_source_author_stats = df_source_author_stats.orderBy(col(\"count\").desc())\n",
    "\n",
    "# Exibir os resultados\n",
    "df_source_author_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32fc26ce-ae96-4f1e-8552-195d357e00b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------+------------+-------------+\n|year|month|sum_DNA|sum_genetics|sum_treatment|\n+----+-----+-------+------------+-------------+\n|2024|    9|     12|           2|            1|\n|2024|   10|     11|           3|            5|\n+----+-----+-------+------------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Adicionar colunas de contagem de palavras-chave (1 se a palavra aparecer, 0 caso contrário)\n",
    "for keyword in criteria.keywords:\n",
    "    df = df.withColumn(keyword, when(col(\"conteudo\").contains(keyword), 1).otherwise(0))\n",
    "\n",
    "# Agrupar por ano, mês e dia e somar as aparições das palavras-chave\n",
    "df_keyword_stats = df.groupBy(\n",
    "    year(col(\"data_publicacao\")).alias(\"year\"),\n",
    "    month(col(\"data_publicacao\")).alias(\"month\")    \n",
    ").agg(*[sum(col(keyword)).alias(f\"sum_{keyword}\") for keyword in criteria.keywords])\n",
    "\n",
    "# Exibir os resultados\n",
    "df_keyword_stats.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 912719646809540,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "07.visualization",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
